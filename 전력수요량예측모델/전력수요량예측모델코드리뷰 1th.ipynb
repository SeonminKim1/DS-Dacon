{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 전력 수요량 예측 경진대회 코드리뷰 - 1위 + 개인추가\n",
    "- https://dacon.io/competitions/official/196878/codeshare/418?page=1&dtype=recent&ptype=pub\n",
    "\n",
    "### 배경\n",
    "- 전력수요예측 시뮬레이션을 통한 효율적인 빅데이터 분석기법 발굴\n",
    "- 전력 융합신서비스 발굴 및 비즈니스 모델 개발 활용\n",
    "- 창의적인 아이디어와 빅데이터 분석기술을 토대로 에너지 신서비스 개발 촉진\n",
    "\n",
    "### 문제\n",
    "- 본 대회에서는, 기존 전력 사용 기록과 기상 데이터 등 공공 데이터를 이용하여, 각 가정 및 회사의 시간별, 일별, 월별 전력 사용량을 예측합니다. **2018년 7월1일부터 2018년 - 11월 30일까지의 에너지 사용량을 예측**합니다. 보다 정확히는 다음을 예측합니다.\n",
    "- 2018년 **7월 1일 00시부터 24시까지**, 24시간, ‘시간당 전력사용량’ (24개) \n",
    "- 2018년 **7월 1일부터 7월10일까지, 10일간**, ‘일간 전력사용량’ (10개)\n",
    "- 2018년 **7월 부터 11월까지, 5개월간**, ‘월간 전력사용량’ (5개)\n",
    "- 즉 각 세대(또는 상가)당 39개(24개,10개,5개)의 값을 예측해야 합니다.\n",
    "\n",
    "### 데이터\n",
    "- 본 대회에서는 2016년 7월 20일부터 2018년 6월 30일까지의 국내 특정 지역의 아파트들과 상가의 전력에너지 사용량이 주어집니다. 자세한 사항은 첨부파일로 포함합니다.\n",
    "- * 주의: 제공되는 데이터에는 결측치나 이상치(NA, 0인 값)가 포함되어 있습니다. 대회참가자들은 이러한 결측치를 고려하여, 결측치 처리 등 예측 기법을 적용하여야 합니다.\n",
    "- 참고로, NA가 발생한 경우, 직전 시간의 전력사용량 값이 상당히 큰 경향이 있습니다. 이는 미터링 데이터 수집 시스템의 특징으로 보입니다. 그러나 반드시 그런 것은 아닙니다.\n",
    "\n",
    "#### ① train.csv\n",
    "- 국내(인천지역) 특정 지역의 모 아파트 및 모 상가의 전력사용량. (1300호)\n",
    "- 2016년 7월 26일 11시 ~ 2018년 6월 30일 24시까지 시간 당 전력사용량\n",
    "\n",
    "#### ② test.csv\n",
    "- 국내(인천지역) 특정 지역의 모 아파트 및 모 상가의 전력사용량. (200호)\n",
    "- 2017년 7월 1일 00시 ~ 2018년 6월 30일 24시까지 시간 당 전력사용량\n",
    "* train의 세대와 다른 세대\n",
    "\n",
    "#### ③ submission.csv\n",
    "- test셋에 제시된 세대(상가)에 대한 예측값들을 제출하는 포맷\n",
    "- 본 대회에서는 2016년 7월 20일부터 2018년 6월 30일까지의 국내 특정 지역의 아파트들과 상가의 전력에너지 사용량이 주어집니다. 자세한 사항은 첨부파일로 포함\n",
    "\n",
    "#### ④ weather.csv\n",
    "- 인천_시간별__기상자료(16-18)_축소__7월1일.csv (16.07.20 0:00 ~ 18.7.1 23:00)\n",
    "- 인천_월별_기상자료(16-18)_축소.csv\n",
    "- 인천_일별_기상자료(16-18)_축소.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 777\n",
      "Numpy: 1.18.1\n",
      "Pandas: 0.25.3\n",
      "LightGBM: 2.3.1\n",
      "Scikit-Learn: 0.22.2\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf8-*-\n",
    "# General Library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Machine Learning Library\n",
    "import lightgbm as lgb\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set Random Seed\n",
    "seed = 777\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "# Print Information\n",
    "print('Seed: %i'%(seed))\n",
    "print('Numpy: %s'%(np.__version__))\n",
    "print('Pandas: %s'%(pd.__version__))\n",
    "print('LightGBM: %s'%(lgb.__version__))\n",
    "print('Scikit-Learn: %s'%(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_dataset(dataset):\n",
    "    '''\n",
    "    This function sorts the meteric_id of train.csv and test.csv into numerical order.\n",
    "    '''\n",
    "    columns = dataset.columns\n",
    "    meter_ids = columns[1:]\n",
    "    tmp = []\n",
    "    for meter_id in meter_ids:\n",
    "        meter_id = meter_id.replace('X', '')\n",
    "        tmp.append(int(meter_id)) \n",
    "    tmp = np.sort(tmp)\n",
    "\n",
    "    meter_ids = []\n",
    "    for meter_id in tmp:\n",
    "        meter_id = 'X' + str(meter_id)\n",
    "        meter_ids.append(meter_id)\n",
    "\n",
    "    results = [dataset[columns[0]].values]\n",
    "    for meter_id in meter_ids:\n",
    "        values = dataset[meter_id].values\n",
    "        results.append(values)\n",
    "    results = np.array(results).T\n",
    "    df = pd.DataFrame(results, columns=[columns[0]] + meter_ids)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data -> 원래 sort_dataset이 있었는데 굳이 의미 없는듯\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "\n",
    "# Weather data\n",
    "with open('data/인천_시간별__기상자료(16-18)_축소__7월1일.csv') as file:\n",
    "    additional = []\n",
    "    for line in file.readlines():\n",
    "        line = line.replace(',\\n', ',nan')\n",
    "        line = line.replace('\\n', '')\n",
    "        line = line.replace('뇌우끝,비', '뇌우끝_비')\n",
    "        line = line.replace('뇌우,비눈', '뇌우_비눈')\n",
    "        line = line.replace('뇌우끝,눈', '뇌우끝_눈')\n",
    "        line = line.replace(',,', ',nan,')\n",
    "        line = line.replace(',,', ',nan,')\n",
    "        additional.append(line.split(','))\n",
    "        \n",
    "additional = np.array(additional)\n",
    "additional_columns = additional[0]\n",
    "additional_datas = additional[1:]\n",
    "additional_datas_float = []\n",
    "\n",
    "for i in range(len(additional_columns)):\n",
    "    additional_data = additional_datas[:, i]\n",
    "    try:\n",
    "        tmp = additional_data.astype(float)\n",
    "        additional_datas_float.append(tmp)\n",
    "    except:\n",
    "        tmp = additional_data.astype(str)\n",
    "        additional_datas_float.append(tmp)\n",
    "\n",
    "# 시간 바꿔주고\n",
    "add_times = []\n",
    "for item in additional_datas_float[1]:\n",
    "    new_time = datetime.datetime.strptime(item, '%Y.%m.%d %H:%M')\n",
    "    add_times.append(new_time)\n",
    "add_times = np.array(add_times)\n",
    "\n",
    "# 온도\n",
    "temperature = additional_datas_float[2]\n",
    "for i in range(len(temperature)):\n",
    "    if np.isnan(temperature[i]):\n",
    "        temperature[i] = temperature[i-1]        \n",
    "        \n",
    "# 강수량\n",
    "rainfall = additional_datas_float[3]\n",
    "rainfall[np.where(np.isnan(rainfall) == True)[0]] = 0\n",
    "\n",
    "# 풍속\n",
    "wind = additional_datas_float[4]\n",
    "\n",
    "# 습도\n",
    "humidity = additional_datas_float[5]\n",
    "for i in range(len(humidity)):\n",
    "    if np.isnan(humidity[i]):\n",
    "        humidity[i] = humidity[i-1]\n",
    "        \n",
    "# 적설량\n",
    "snowfall = additional_datas_float[6]\n",
    "snowfall[np.where(np.isnan(snowfall) == True)[0]] = 0\n",
    "\n",
    "# 구름\n",
    "cloud = additional_datas_float[8]\n",
    "for i in range(len(cloud)):\n",
    "    if np.isnan(cloud[i]):\n",
    "        cloud[i] = cloud[i-1]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 전처리\n",
    "#### Data Cleansing & Pre-Processing\n",
    "- 1) train, test의 결측치를 모두 0으로 변경합니다.\n",
    "    - a. 결측치는 모두 0으로 변경 -> NAN 전부 0으로\n",
    "    - b. 0.003 보다 작은 값은 0으로 변경 -> 0.003을 0으로.??? - 아마 0.003이하가 많은경우를 시각화 해봤어야 했을듯? -> 0.003이 노이즈라는 것에 대한 어느정도의 근거? 이론?\n",
    "    - c. 시간별 전력을 하루 단위로 합쳐 날짜별 전력으로 변경\n",
    "    - d. 유효한 데이터만 사용하기 위해 앞뒤로 0인 구간을 삭제\n",
    "    - e. 데이터 중간에 0이 있는 경우 값 변경 (ex. 평균값)\n",
    "\n",
    "- 2) 날짜의 타입을 datetime 으로 변경합니다.\n",
    "- 3) 시간별 날씨 데이터를 평균을 이용하여 일자별 날씨로 변경합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜 타입 변경\n",
    "def time_convert(df_time, string_type='train'):\n",
    "    '''\n",
    "    This function changes format of time from string to datetime.\n",
    "    '''\n",
    "    old_times = df_time\n",
    "    new_times = old_times.copy()\n",
    "    for i, old_time in enumerate(old_times):\n",
    "        if string_type == 'train':\n",
    "            new_time = datetime.datetime.strptime(old_time, '%Y-%m-%d %H:%M')\n",
    "        elif string_type == 'test':\n",
    "            new_time = datetime.datetime.strptime(old_time, '%Y.%m.%d %H:%M')\n",
    "        else:\n",
    "            new_time = datetime.datetime.strptime(old_time, '%Y-%m-%d')\n",
    "        new_times[i] = new_time\n",
    "    return new_times\n",
    "\n",
    "# 전력소비량 데이터와 기상 데이터를 일별로 바꿔줌\n",
    "def split_day(_times, _datas):\n",
    "    '''\n",
    "    This function splits power consumption data and weather data by days.\n",
    "    '''\n",
    "    for time in _times:\n",
    "        if time.time().hour == 0:\n",
    "            ref_time = time.date()\n",
    "            break \n",
    "    times = []\n",
    "    datas = []\n",
    "    data_tmp = []\n",
    "    for i, time in enumerate(_times):\n",
    "        time = time.date()\n",
    "        data = _datas[i]\n",
    "        if ref_time > time:\n",
    "            pass\n",
    "        elif ref_time == time:\n",
    "            data_tmp.append(data)\n",
    "        else:\n",
    "            times.append(ref_time)\n",
    "            datas.append(data_tmp)\n",
    "            ref_time = time\n",
    "            data_tmp = [data]\n",
    "    if ref_time not in times:\n",
    "        if len(data_tmp) == 24:\n",
    "            times.append(ref_time)\n",
    "            datas.append(data_tmp)\n",
    "    times = np.array(times)\n",
    "    datas = np.array(datas)\n",
    "    return times, datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repalce nan to zero\n",
    "train = train.replace(np.nan, 0.0)\n",
    "test = test.replace(np.nan, 0.0)\n",
    "\n",
    "# Convert time data format to datetime\n",
    "train_times = time_convert(train['Time'], string_type='train').values\n",
    "test_times = time_convert(test['Time'], string_type='test').values\n",
    "\n",
    "# Meter id\n",
    "train_meter_ids = train.columns[1:]\n",
    "test_meter_ids = test.columns[1:]\n",
    "\n",
    "# Downsampling (a day) - 다운샘플링\n",
    "temperature = np.mean(split_day(add_times, temperature)[1], axis=1) # 일단위로 바꿔진 온도\n",
    "rainfall = np.mean(split_day(add_times, rainfall)[1], axis=1) # 일단위로 바꿔진 강수량\n",
    "wind = np.mean(split_day(add_times, wind)[1], axis=1) # 일단위로 바꿔진 풍속량\n",
    "humidity = np.mean(split_day(add_times, humidity)[1], axis=1) # 일단위로 바꿔진 습도량\n",
    "snowfall = np.mean(split_day(add_times, snowfall)[1], axis=1) # 일단위로 바꿔진 적설량\n",
    "add_times, cloud = split_day(add_times, cloud) # 일단위로 바꿔진 구름양\n",
    "cloud = np.mean(cloud, axis=1) # 구름양\n",
    "\n",
    "# Make additional data set\n",
    "additional_data = np.array([   \n",
    "    add_times, # 시간\n",
    "    temperature, # 온도\n",
    "    rainfall, # 강수량\n",
    "    wind, # 바람 \n",
    "    humidity, # 습도\n",
    "    snowfall, # 적설량\n",
    "    cloud, # 구름양\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[datetime.datetime(2016, 7, 26, 11, 0)\n",
      " datetime.datetime(2016, 7, 26, 12, 0)\n",
      " datetime.datetime(2016, 7, 26, 13, 0)\n",
      " datetime.datetime(2016, 7, 26, 14, 0)\n",
      " datetime.datetime(2016, 7, 26, 15, 0)] \n",
      "\n",
      "[datetime.datetime(2017, 7, 1, 0, 0) datetime.datetime(2017, 7, 1, 1, 0)\n",
      " datetime.datetime(2017, 7, 1, 2, 0) datetime.datetime(2017, 7, 1, 3, 0)\n",
      " datetime.datetime(2017, 7, 1, 4, 0)] \n",
      "\n",
      "[[datetime.date(2016, 7, 20) datetime.date(2016, 7, 21)\n",
      "  datetime.date(2016, 7, 22) ... datetime.date(2018, 6, 29)\n",
      "  datetime.date(2018, 6, 30) datetime.date(2018, 7, 1)]\n",
      " [27.8875 27.94583333333333 28.4375 ... 22.4375 23.708333333333332 22.125]\n",
      " [0.0 0.0 0.0 ... 0.016666666666666666 0.0 2.466666666666667]\n",
      " ...\n",
      " [90.58333333333333 86.54166666666667 89.25 ... 90.20833333333333\n",
      "  84.91666666666667 94.29166666666667]\n",
      " [0.0 0.0 0.0 ... 0.0 0.0 0.0]\n",
      " [6.708333333333333 8.0 4.708333333333333 ... 7.791666666666667 9.375\n",
      "  9.791666666666666]]\n"
     ]
    }
   ],
   "source": [
    "print(train_times[:5],'\\n') # 연도, 월, 일, 시간, 분 (16년도 7월 26일 ~)\n",
    "print(test_times[:5],'\\n') # 연도, 월, 일, 시간, 분 (17년도 7월 1일 ~)\n",
    "print(additional_data[:8]) # 7, 712 / times, 온도, 강수량, 바람, 습도, 적설량, 구름양\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 탐색적 자료분석\n",
    "#### Exploratory Data Analysis\n",
    "- 아래 그림은 train.csv, test.csv 내 유효한 데이터 수를 보여줍니다. test.csv는 id 481번 이하로 분포하고 있으며 481번을 기준으로 데이터 수의 분포가 다릅니다. 따라서 모델 생성 시 0 ~ 481번 데이터만 사용하는 것을 고려합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#### 분포 확인\n",
    "# train data \n",
    "train_id_num, train_data_num = [], []\n",
    "for meter_id in train_meter_ids:\n",
    "    meter_num = int(meter_id.replace('NX', ''))\n",
    "    valid_num = len(np.where(train[meter_id] > 0.0)[0])\n",
    "    train_id_num.append(meter_num)\n",
    "    train_data_num.append(valid_num)\n",
    "\n",
    "# test data    \n",
    "test_id_num = []\n",
    "test_data_num = [] \n",
    "\n",
    "for meter_id in test_meter_ids:\n",
    "    meter_num = int(meter_id.replace('NX', ''))\n",
    "    valid_num = len(np.where(test[meter_id] > 0.0)[0])\n",
    "    test_id_num.append(meter_num)\n",
    "    test_data_num.append(valid_num)\n",
    "\n",
    "# scatter plot 으로 점찍어보기\n",
    "plt.scatter(train_id_num, train_data_num, s=5, color='b', label='train')\n",
    "plt.scatter(test_id_num, test_data_num, s=5, color='r', label='test')\n",
    "plt.legend()\n",
    "plt.xlim(0, 1600)\n",
    "plt.ylim(bottom=0)\n",
    "plt.xlabel('Meter Id')\n",
    "plt.ylabel('Data Numer')\n",
    "plt.show()\n",
    "\n",
    "### 결과 실제와 다름 (아마 data가 바뀐듯?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 변수 선택 및 모델 구축\n",
    "#### Feature Engineering & Initial Modeling\n",
    "- 1) 전력 데이터를 meter id 별로 따로 처리합니다.\n",
    "- 2) 전력 데이터는 0.001 단위로 측정되어 있습니다. 너무 작은 측정값은 노이즈가 될 수 있어 0.003 보다 작은 값을 0 으로 변경합니다.\n",
    "- 3) 전력 데이터를 다음 방법으로 정규화하여 사용합니다. (최댓값으로 나눔 > 로그를 씌움 > 평균으로 뺌 > 표준편차로 나눔)\n",
    "- 4) 전력 데이터에 로그를 씌우기 위해 값 0을 처리합니다. (함수 consumption의 missing_value argument)\n",
    "- 5) 전력 데이터에 해당하는 시간을 주기가 365일인 sine 함수를 이용해 인코딩하여 사용합니다. (함수 time_encoder) - 시간은 주기가 365, 최대값이 8월 1일인 사인함수\n",
    "- 6) 전력 데이터에 해당하는 요일을 Feature로 사용합니다. (월=0/6, 화=1/6, 수=2/6, 목=3/6, 금=4/6, 토=5/6, 일=6/6)\n",
    "- 7) 2018.7.1일을 예측하는 모델은 날씨 데이터 사용을 고려합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consumption(_times, _datas, missing_value=None, cutoff=12):\n",
    "    '''\n",
    "    a) This function returns valid power consumption by days. \n",
    "    b) It turns values which are lower than 0.003 into zero.\n",
    "    '''\n",
    "    times, datas = split_day(_times, _datas)\n",
    "    datas[np.where(datas < 3e-3)] = 0.0\n",
    "    tmp = []\n",
    "    for data in datas:\n",
    "        if len(np.where(data > 0.0)[0]) >= cutoff:\n",
    "            out = 24*np.mean(data[np.where(data > 0.0)])\n",
    "            tmp.append(out)\n",
    "        else:\n",
    "            tmp.append(0.0)\n",
    "    datas = np.array(tmp)\n",
    "    \n",
    "    valid_num = len(np.where(datas > 0.0)[0])\n",
    "    if valid_num == 0:\n",
    "        return np.array([]), np.array([])\n",
    "    else:\n",
    "        index_i, index_f = np.where(datas > 0.0)[0][0], np.where(datas > 0.0)[0][-1]\n",
    "        times = times[index_i:index_f+1]\n",
    "        datas = datas[index_i:index_f+1]\n",
    "        if type(missing_value) == type(None):\n",
    "            return times, datas\n",
    "        elif missing_value == 0:\n",
    "            return times, datas\n",
    "        elif missing_value == 1:\n",
    "            for i, data in enumerate(datas):\n",
    "                if data == 0.0:\n",
    "                    if i < 2:\n",
    "                        datas[i] = datas[i-1]\n",
    "                    else:\n",
    "                        datas[i] = 0.2*datas[i-2] + 0.8*datas[i-1]\n",
    "            return times, datas\n",
    "        elif missing_value == 2:\n",
    "            mean = np.mean(datas[np.where(datas > 0.0)])\n",
    "            datas[np.where(datas == 0.0)] = mean\n",
    "            return times, datas\n",
    "        elif missing_value == 3:\n",
    "            mean = gauss_mean(datas[np.where(datas > 0.0)])\n",
    "            datas[np.where(datas == 0.0)] = mean\n",
    "            return times, datas\n",
    "        else:\n",
    "            print('missing_value should be in [0, 1, 2, 3]')\n",
    "            raise ValueError\n",
    "\n",
    "def distribution_in_day(_times, _datas, set_weekday=6, start=(2018, 3, 1), cutoff=12):\n",
    "    '''\n",
    "    This function returns power consumption distribution in a day.\n",
    "    '''    \n",
    "    start_year, start_month, start_day = start\n",
    "    times, datas = split_day(_times, _datas)\n",
    "    dist = []\n",
    "    for i, data in enumerate(datas):\n",
    "        if times[i] >= datetime.date(start_year, start_month, start_day):\n",
    "            if times[i].weekday() == set_weekday:\n",
    "                if len(np.where(data > 0.0)[0]) >= cutoff:             \n",
    "                    data = data/np.sum(data)\n",
    "                    dist.append(data)\n",
    "    dist = np.array(dist)\n",
    "    dist = gauss_mean(dist, axis=0)\n",
    "    dist = dist/np.sum(dist)\n",
    "    return dist\n",
    "\n",
    "def sequence_id(\n",
    "    size, times, consums, use_weekdays=False, \n",
    "    use_times=False, add_data_sets=None, reverse=False):\n",
    "    '''\n",
    "    This function makes a sequence for input of a model.\n",
    "    '''   \n",
    "    use_additional = False\n",
    "    if type(add_data_sets) != type(None):\n",
    "        use_additional = True\n",
    "        add_times = add_data_sets[0]\n",
    "        add_data_sets = add_data_sets[1:]\n",
    "    if reverse:\n",
    "        times = times[::-1]\n",
    "        consums = consums[::-1]\n",
    "        if use_additional:\n",
    "            add_times = add_times[::-1]\n",
    "            add_data_sets = add_data_sets[:, ::-1]    \n",
    "    if use_additional:\n",
    "        ix = np.where(add_times==times[0])[0].item()\n",
    "\n",
    "    i = 0\n",
    "    sequence = []\n",
    "    while True:\n",
    "        times_select = times[i:i+size]\n",
    "        consums_select = consums[i:i+size]\n",
    "        if len(consums_select) == size:\n",
    "            length = len(times_select)\n",
    "            select = []\n",
    "            if use_additional:\n",
    "                for add_data_set in add_data_sets:\n",
    "                    select.append(add_data_set[i+ix:i+ix+length])\n",
    "            if use_times:\n",
    "                time_encoded = []\n",
    "                for time in times_select:                \n",
    "                    time = time_encoder(time)\n",
    "                    time_encoded.append(time)\n",
    "                select.append(time_encoded)\n",
    "            if use_weekdays:\n",
    "                weekdays = []\n",
    "                for time in times_select:\n",
    "                    weekday = time.weekday()   \n",
    "                    weekday /= 6\n",
    "                    weekdays.append(weekday)\n",
    "                select.append(weekdays)\n",
    "            select.append(consums_select)\n",
    "\n",
    "            seq = np.dstack(select)\n",
    "            seq = seq.flatten()\n",
    "            sequence.append(seq)\n",
    "            i += 1\n",
    "        else:\n",
    "            sequence = np.array(sequence)\n",
    "            break\n",
    "    return sequence\n",
    "\n",
    "def sequence_prediction(\n",
    "    iteration, size, model, times, consums, \n",
    "    use_weekdays=False, use_times=False, add_data_sets=None, reverse=False):\n",
    "    '''\n",
    "    This function is for prediction (iteratable).\n",
    "    '''\n",
    "    use_additional = False\n",
    "    if type(add_data_sets) != type(None):\n",
    "        use_additional = True\n",
    "        add_times = add_data_sets[0]\n",
    "        add_data_sets = add_data_sets[1:]\n",
    "    if reverse:\n",
    "        times = times[::-1]\n",
    "        consums = consums[::-1]\n",
    "        if use_additional:\n",
    "            add_times = add_times[::-1]\n",
    "            add_data_sets = add_data_sets[:, ::-1]\n",
    "\n",
    "    len_ini = len(times)\n",
    "    times_pred = times.copy()\n",
    "    consums_pred = consums.copy()\n",
    "    for _ in range(iteration):\n",
    "        times_select = times_pred[-(size-1):]\n",
    "        if reverse:\n",
    "            times_select = np.append(times_select, times_select[-1] + datetime.timedelta(days=-1))\n",
    "        else:\n",
    "            times_select = np.append(times_select, times_select[-1] + datetime.timedelta(days=1))\n",
    "        consums_select = consums_pred[-(size-1):]\n",
    "        consums_select = np.append(consums_select, 0.0)\n",
    "        length = len(times_select)\n",
    "\n",
    "        select = []\n",
    "        if use_additional:\n",
    "            ix = np.where(add_times==times_select[0])[0].item()\n",
    "            for add_data_set in add_data_sets:\n",
    "                select.append(add_data_set[ix:ix+length])\n",
    "        if use_times:\n",
    "            time_encoded = []\n",
    "            for time in times_select:                \n",
    "                time = time_encoder(time)\n",
    "                time_encoded.append(time)\n",
    "            select.append(time_encoded)\n",
    "        if use_weekdays:\n",
    "            weekdays = []\n",
    "            for time in times_select:\n",
    "                weekday = time.weekday()    \n",
    "                weekday /= 6            \n",
    "                weekdays.append(weekday)\n",
    "            select.append(weekdays)\n",
    "        select.append(consums_select)\n",
    "\n",
    "        seq = np.dstack(select)\n",
    "        seq = seq.flatten()[:-1]\n",
    "        x_pred = seq.reshape(1, len(seq))\n",
    "        y_pred = model.predict(x_pred)\n",
    "\n",
    "        times_pred = np.append(times_pred, times_select[-1])\n",
    "        consums_pred = np.append(consums_pred, y_pred)        \n",
    "    times_pred = times_pred[len_ini:]\n",
    "    consums_pred = consums_pred[len_ini:]\n",
    "    return times_pred, consums_pred\n",
    "\n",
    "# 정규화 함수\n",
    "def normalization(datas):\n",
    "    '''\n",
    "    The input is subtracted by its mean value and than divided by its standard deviation.\n",
    "    '''\n",
    "    mean = np.mean(datas)\n",
    "    std = np.std(datas)\n",
    "    norm = (datas - mean) / std\n",
    "    return norm, mean, std\n",
    "\n",
    "# 가우스 정규분포?\n",
    "def gauss_mean(output, axis=0):\n",
    "    '''\n",
    "    This function returns gaussian weighted mean value of the input.\n",
    "    '''    \n",
    "    if output.shape[axis] <= 1:\n",
    "        return np.mean(output, axis=axis)\n",
    "    else:\n",
    "        std = np.std(output, axis=axis)\n",
    "        mean = np.mean(output, axis=axis)    \n",
    "        gauss = 1/(std*np.sqrt(2*np.pi))*np.exp(-0.5 * np.square((output-mean)/std))    \n",
    "        gauss_mean = np.sum(gauss*output, axis=axis)/np.sum(gauss, axis=axis)\n",
    "        return gauss_mean\n",
    "\n",
    "#  전력 데이터에 해당하는 시간을 주기가 365일인 sine 함수를 이용해 인코딩하여 사용\n",
    "def time_encoder(time):\n",
    "    '''\n",
    "    This function encodes time data into a number using sine wave function (period = 365 days).\n",
    "    '''\n",
    "    dt = time - datetime.date(2018, 8, 1)\n",
    "    dt = dt.days\n",
    "    output = np.cos(2*np.pi*dt/365)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가지표들\n",
    "# smape\n",
    "def smape(array_1, array_2):\n",
    "    '''\n",
    "    This function calculates SMAPE between two lists.\n",
    "    '''\n",
    "    score = 100*np.mean(2*abs(array_1 - array_2)/(abs(array_1)+abs(array_2)))\n",
    "    return score\n",
    "\n",
    "# r2_score\n",
    "def r2_score(list_1, list_2):\n",
    "    '''\n",
    "    This function calculates R2 score between two lists.\n",
    "    '''\n",
    "    score = np.square(np.corrcoef(list_1, list_2)[0][1])\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def lgb_train(x_train, x_valid, y_train, y_valid, feature_name=None, plot=False):\n",
    "    '''\n",
    "    This function returns a trained LightGBM model.\n",
    "    '''\n",
    "    lgb_train = lgb.Dataset(x_train, label = y_train)\n",
    "    lgb_valid = lgb.Dataset(x_valid, label = y_valid)    \n",
    "    params = {\n",
    "        'random_seed': seed,\n",
    "        'bagging_seed': seed,\n",
    "        'feature_fraction_seed': seed,\n",
    "        'data_random_seed': seed,\n",
    "        'drop_seed': seed,\n",
    "        \n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'huber',\n",
    "        'learning_rate': 0.04,\n",
    "        'num_leaves': 63,\n",
    "        'max_depth': -1,\n",
    "        'bagging_fraction': 0.1,\n",
    "        'feature_fraction': 0.4,\n",
    "        'lambda_l1': 10.0,\n",
    "        'lambda_l2': 30.0,\n",
    "        'max_bin': 255,\n",
    "    }    \n",
    "    model = lgb.train(\n",
    "        params, \n",
    "        lgb_train, \n",
    "        valid_sets = lgb_valid,\n",
    "        num_boost_round = 1 # 2000,\n",
    "        early_stopping_rounds = 100,\n",
    "        verbose_eval = 200,\n",
    "        feature_name = feature_name,\n",
    "    )\n",
    "    if type(feature_name) != type(None):\n",
    "        lgb.plot_importance(model, figsize=(5, len(feature_name)//5))\n",
    "        plt.show()\n",
    "    if plot:\n",
    "        true = y_valid\n",
    "        pred = model.predict(x_valid)\n",
    "        score = r2_score(true, pred)\n",
    "        plt.title('R2: %f'%(score))\n",
    "        plt.scatter(true, pred)\n",
    "        plt.plot([true.min(), true.max()], [true.min(), true.max()], color='k')\n",
    "        plt.show()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature\n",
    "1. 전력 데이터 정규화 (*meter id 별로 따로 처리)\n",
    "> 최대값으로 나눔 > 로그를 씌움 > 평균으로 뺌 > 표준편차로 나눔\n",
    "2. 전력데이터에 해당하는 날짜의 시간, 요일 정보를 사용\n",
    "> 시간은 주기가 365일, 최대값이 8월 1일인 사인함수를 사용\n",
    "3. 2018.07.01 을 예측하는 경우 날씨 데이터 사용을 고려함\n",
    "\n",
    "#### ======= ####\n",
    "#### 7월 1일 ~ 10일 / 7월 ~ 11월\n",
    "4. 2018.07.01 이후를 예측하는 경우 날씨 데이터 사용 X\n",
    "5. 예측하는 날의 약 10주 전 데이터를 모아 1차원 벡터로 사용 - 2등 방식과 똑같음 / 계절성은 부여하기가 힘듬.?  => 확실히 시계열 할때 계절로 나누는게 날려나?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 모델 학습 및 검증\n",
    "#### Model Tuning & Evaluation\n",
    "- 1) 조건에 따라 18개 모델을 생성합니다.\n",
    "    - a) Meter ID 범위: 0 ~ 481 / 0 ~ 1500\n",
    "    - b) 전력 데이터 중 0 에 대한 처리를 3종류로 분류 (missing_value = 1, 2, and 3)\n",
    "    - c) 2018.07.01 예측에 날씨 데이터 사용 여부\n",
    "    - d) 날씨 데이터 사용 시 2018.07.01 이후 예측을 위해 데이터 길이 여부 (74일 / 75일)\n",
    "- 2) 2018.7.1(일요일)의 시간별 예측을 위해 2018.3.1~2018.6.30 중 일요일에 해당하는 데이터를 사용합니다. gaussian weighted mean을 사용해 시간에 따른 분포를 구하여 예측합니다. (함수 gauss_mean)\n",
    "- 3) 첫 loop에서 'temp/' 폴더를 생성하며 각 모델은 submission과 동일한 포맷의 파일을 'temp/' 폴더 안에 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(file_name, set_last_id_num=481, missing_value=2, sizes=[74, 74], pred_sizes=[1, 152], additional=False, two_step=False):\n",
    "    '''\n",
    "    a) This function trains a model (or two models) and predicts future power consumptions.\n",
    "    b) This function makes a directory 'temp/' and writes a temporary result file in the directory.\n",
    "    '''    \n",
    "    start_time = time.time()\n",
    "    # Set meter id range and missing value process\n",
    "    set_last_id_num = set_last_id_num\n",
    "    missing_value = missing_value\n",
    "    \n",
    "    # Make a dictionary with valid data\n",
    "    valid_data = {}\n",
    "    for meter_id in train_meter_ids:\n",
    "        id_num = int(meter_id.replace('NX', ''))\n",
    "        if id_num <= set_last_id_num:\n",
    "            times, consums = consumption(train_times, train[meter_id], missing_value=missing_value)\n",
    "            valid_data[meter_id] = {'time': times, 'data': consums}\n",
    "            print('Loading: %5s'%(meter_id), end='\\r')\n",
    "    for meter_id in test_meter_ids:\n",
    "        id_num = int(meter_id.replace('NX', ''))\n",
    "        if id_num <= set_last_id_num:\n",
    "            times, consums = consumption(test_times, test[meter_id], missing_value=missing_value)\n",
    "            valid_data[meter_id] = {'time': times, 'data': consums}\n",
    "            print('Loading: %5s'%(meter_id), end='\\r')\n",
    "\n",
    "    # Meter id list\n",
    "    meter_ids = np.array(list(valid_data.keys()))\n",
    "    meter_num = []\n",
    "    for meter_id in meter_ids:\n",
    "        num = int(meter_id.replace('NX', ''))\n",
    "        meter_num.append(num)\n",
    "    meter_num = np.array(meter_num)\n",
    "    meter_ids = meter_ids[np.argsort(meter_num)]\n",
    "    \n",
    "    # Data set parameters\n",
    "    size = sizes[0]\n",
    "    use_weekdays = True\n",
    "    use_times = True\n",
    "    if additional:\n",
    "        add_data_sets = additional_data\n",
    "    else:\n",
    "        add_data_sets = None\n",
    "    valid_data_added = valid_data.copy()\n",
    "\n",
    "    # Make train/validation/test set\n",
    "    X_, y_ = [], []\n",
    "    for meter_id in meter_ids:\n",
    "        times, consums = valid_data_added[meter_id]['time'], valid_data_added[meter_id]['data']\n",
    "        if len(consums) >= size:\n",
    "            data_in = consums/np.max(consums)\n",
    "            data_in = np.log(data_in)\n",
    "            data_in = normalization(data_in)[0]\n",
    "            sequence = sequence_id(\n",
    "                size, times, data_in, \n",
    "                use_weekdays=use_weekdays, use_times=use_times, add_data_sets=add_data_sets, reverse=False)\n",
    "            X, y = sequence[:, :-1], sequence[:, -1]\n",
    "            X_.append(X)\n",
    "            y_.append(y)\n",
    "    X_, y_ = np.concatenate(X_, axis=0).astype('float'), np.concatenate(y_, axis=0).astype('float')\n",
    "    x_train, x_remain, y_train, y_remain = train_test_split(X_, y_, test_size = 0.2, random_state=seed)\n",
    "    x_valid, x_test, y_valid, y_test = train_test_split(x_remain, y_remain, test_size = 0.5, random_state=seed)\n",
    "    print('Feature: %i, Total: %i, Train: %i, Validation: %i, Test: %i'\n",
    "          %(X_.shape[1], X_.shape[0], x_train.shape[0], x_valid.shape[0], x_test.shape[0]))\n",
    "    \n",
    "    # Train model 1\n",
    "    lgb_model = lgb_train(x_train, x_valid, y_train, y_valid, feature_name=None, plot=False)\n",
    "    lgb_test, lgb_valid = lgb_model.predict(x_test).flatten(), lgb_model.predict(x_valid).flatten()\n",
    "    lgb_test_score, lgb_valid_score = r2_score(y_test, lgb_test), r2_score(y_valid, lgb_valid)\n",
    "    print('Test score: %f, Valid score: %f'%(lgb_test_score, lgb_valid_score))\n",
    "    \n",
    "    # Predict 2018.7.1\n",
    "    pred_size = pred_sizes[0]\n",
    "    if two_step:\n",
    "        selected_meter_ids = meter_ids\n",
    "    else:\n",
    "        selected_meter_ids = test_meter_ids\n",
    "    for meter_id in selected_meter_ids:\n",
    "        times, consums = valid_data_added[meter_id]['time'], valid_data_added[meter_id]['data']\n",
    "        if len(times) >= size-1:            \n",
    "            consums_max = np.max(consums)\n",
    "            data_in = consums/consums_max\n",
    "            data_in = np.log(data_in)\n",
    "            data_in, mean, std = normalization(data_in)        \n",
    "            pred_times, pred_consums = sequence_prediction(\n",
    "                pred_size, size, lgb_model, times, data_in, \n",
    "                use_weekdays=use_weekdays, use_times=use_times, add_data_sets=add_data_sets, reverse=False)\n",
    "            pred_consums = pred_consums*std+mean\n",
    "            pred_consums = np.exp(pred_consums)\n",
    "            pred_consums = pred_consums*consums_max\n",
    "            last_day = pred_times[-1]\n",
    "            times = np.append(times, pred_times)\n",
    "            consums = np.append(consums, pred_consums)\n",
    "            valid_data_added[meter_id] = {'time': times, 'data': consums}        \n",
    "        else:\n",
    "            valid_data_added[meter_id] = {'time': times, 'data': consums} \n",
    "    print('Last Day: {}'.format(last_day))\n",
    "    \n",
    "    if two_step:\n",
    "        # Data set parameters\n",
    "        size = sizes[1]\n",
    "        use_weekdays = True\n",
    "        use_times = True\n",
    "        add_data_sets = None\n",
    "\n",
    "        # Make train/validation/test set\n",
    "        X_, y_ = [], []\n",
    "        for meter_id in meter_ids:\n",
    "            times, consums = valid_data_added[meter_id]['time'], valid_data_added[meter_id]['data']\n",
    "            if len(times) >= size:\n",
    "                data_in = consums/np.max(consums)\n",
    "                data_in = np.log(data_in)\n",
    "                data_in = normalization(data_in)[0]\n",
    "                sequence = sequence_id(\n",
    "                    size, times, data_in, \n",
    "                    use_weekdays=use_weekdays, use_times=use_times, add_data_sets=add_data_sets, reverse=False)\n",
    "                X, y = sequence[:, :-1], sequence[:, -1]\n",
    "                X_.append(X)\n",
    "                y_.append(y)\n",
    "        X_, y_ = np.concatenate(X_, axis=0).astype('float'), np.concatenate(y_, axis=0).astype('float')\n",
    "        x_train, x_remain, y_train, y_remain = train_test_split(X_, y_, test_size = 0.2, random_state=seed)\n",
    "        x_valid, x_test, y_valid, y_test = train_test_split(x_remain, y_remain, test_size = 0.5, random_state=seed)\n",
    "        print('Feature: %i, Total: %i, Train: %i, Validation: %i, Test: %i'\n",
    "              %(X_.shape[1], X_.shape[0], x_train.shape[0], x_valid.shape[0], x_test.shape[0]))\n",
    "\n",
    "        # Train model 2\n",
    "        lgb_model = lgb_train(x_train, x_valid, y_train, y_valid, feature_name=None, plot=False)\n",
    "        lgb_test, lgb_valid = lgb_model.predict(x_test).flatten(), lgb_model.predict(x_valid).flatten()\n",
    "        lgb_test_score, lgb_valid_score = r2_score(y_test, lgb_test), r2_score(y_valid, lgb_valid)\n",
    "        print('Test score: %f, Valid score: %f'%(lgb_test_score, lgb_valid_score))\n",
    "\n",
    "        # Predict 2018.7.2 ~ 2018.11.30\n",
    "        pred_size = pred_sizes[1]\n",
    "        for meter_id in test_meter_ids:\n",
    "            times, consums = valid_data_added[meter_id]['time'], valid_data_added[meter_id]['data']\n",
    "            if len(times) >= size-1:\n",
    "                consums_max = np.max(consums)\n",
    "                data_in = consums/consums_max\n",
    "                data_in = np.log(data_in)\n",
    "                data_in, mean, std = normalization(data_in)\n",
    "                pred_times, pred_consums = sequence_prediction(\n",
    "                    pred_size, size, lgb_model, times, data_in,\n",
    "                    use_weekdays=use_weekdays, use_times=use_times, add_data_sets=add_data_sets, reverse=False)\n",
    "                pred_consums = pred_consums*std+mean\n",
    "                pred_consums = np.exp(pred_consums)\n",
    "                pred_consums = pred_consums*consums_max    \n",
    "                last_day = pred_times[-1]\n",
    "                times = np.append(times, pred_times)\n",
    "                consums = np.append(consums, pred_consums)\n",
    "                valid_data_added[meter_id] = {'time': times, 'data': consums}        \n",
    "            else:\n",
    "                valid_data_added[meter_id] = {'time': times, 'data': consums} \n",
    "        print('Last Day: {}'.format(last_day))\n",
    "    \n",
    "    # Write a result file  \n",
    "    dir_name = 'temp/'\n",
    "    if not os.path.isdir(dir_name):\n",
    "        os.mkdir(dir_name)\n",
    "    file_name = file_name   \n",
    "    submission = pd.read_csv('data/submission_1002.csv')\n",
    "    submission_meter_ids = submission['meter_id'].values\n",
    "    for i, meter_id in enumerate(submission_meter_ids):\n",
    "        times, consums = test_times, test[meter_id]\n",
    "        distribution = distribution_in_day(times, consums, set_weekday=6, start=(2018, 3, 1))\n",
    "\n",
    "        times, consums = valid_data_added[meter_id]['time'], valid_data_added[meter_id]['data']\n",
    "        index_i = np.where(times == datetime.date(2018, 7, 1))[0].item()\n",
    "        index_f = np.where(times == datetime.date(2018, 11, 30))[0].item()\n",
    "        times, consums = times[index_i:index_f+1], consums[index_i:index_f+1]\n",
    "\n",
    "        output_2018_7_1_h = distribution * consums[0]\n",
    "        output_2018_7_1_10_d = consums[0:10]\n",
    "        output_2018_07_m = np.sum(consums[0:31])\n",
    "        output_2018_08_m = np.sum(consums[31:62])\n",
    "        output_2018_09_m = np.sum(consums[62:92])\n",
    "        output_2018_10_m = np.sum(consums[92:123])\n",
    "        output_2018_11_m = np.sum(consums[123:153])\n",
    "        output = np.append([meter_id], output_2018_7_1_h)\n",
    "        output = np.append(output, output_2018_7_1_10_d)\n",
    "        output = np.append(output, [output_2018_07_m, output_2018_08_m, output_2018_09_m, output_2018_10_m, output_2018_11_m])\n",
    "        submission.loc[i] = output\n",
    "\n",
    "    df = pd.DataFrame(submission, columns=submission.columns)\n",
    "    df.to_csv(dir_name + file_name, header=True, index=False)\n",
    "    \n",
    "    # Print the process time\n",
    "    process_time = time.time() - start_time\n",
    "    minute = process_time//60\n",
    "    second = int(process_time - 60*minute)\n",
    "    print('Process Time: %i m %i s'%(minute, second))\n",
    "    print('')\n",
    "    return valid_data_added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 0\n",
      "Feature: 665, Total: 51875, Train: 41500, Validation: 5187, Test: 5188\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's huber: 0.210433\n",
      "[400]\tvalid_0's huber: 0.205026\n",
      "[600]\tvalid_0's huber: 0.204032\n",
      "[800]\tvalid_0's huber: 0.203813\n",
      "Early stopping, best iteration is:\n",
      "[761]\tvalid_0's huber: 0.203785\n",
      "Test score: 0.487841, Valid score: 0.450304\n",
      "Last Day: 2018-07-01\n",
      "Feature: 221, Total: 52351, Train: 41880, Validation: 5235, Test: 5236\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[200]\tvalid_0's huber: 0.215444\n",
      "[400]\tvalid_0's huber: 0.206114\n",
      "[600]\tvalid_0's huber: 0.203555\n",
      "[800]\tvalid_0's huber: 0.202694\n",
      "[1000]\tvalid_0's huber: 0.202268\n",
      "Early stopping, best iteration is:\n",
      "[943]\tvalid_0's huber: 0.202235\n",
      "Test score: 0.487013, Valid score: 0.491687\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'NX1301'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-dbd7c97aeafe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[0mpred_sizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m152\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                 \u001b[0madditional\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                 \u001b[0mtwo_step\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m             )\n\u001b[0;32m     17\u001b[0m         )\n",
      "\u001b[1;32m<ipython-input-8-3de91613bf5b>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(file_name, set_last_id_num, missing_value, sizes, pred_sizes, additional, two_step)\u001b[0m\n\u001b[0;32m    132\u001b[0m         \u001b[0mpred_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred_sizes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmeter_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_meter_ids\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m             \u001b[0mtimes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconsums\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalid_data_added\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmeter_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_data_added\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmeter_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                 \u001b[0mconsums_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconsums\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'NX1301'"
     ]
    }
   ],
   "source": [
    "# Run\n",
    "results = []\n",
    "counter = 0\n",
    "# 481 부터 1500까지 나눔\n",
    "for set_last_id_num in [481, 1500]:\n",
    "    # missing value 종류 3개로 나눔\n",
    "    for missing_value in [1, 2, 3]:\n",
    "        print('Result %i'%(counter))\n",
    "        results.append(\n",
    "            main(\n",
    "                'result_' + str(counter).zfill(2) + '.csv', \n",
    "                set_last_id_num=set_last_id_num, \n",
    "                missing_value=missing_value, \n",
    "                sizes=[74, 74], \n",
    "                pred_sizes=[1, 152], \n",
    "                additional=True, \n",
    "                two_step=True,\n",
    "            )\n",
    "        )\n",
    "        counter += 1\n",
    "        \n",
    "        print('Result %i'%(counter))\n",
    "        \n",
    "        results.append(\n",
    "            main(\n",
    "                'result_' + str(counter).zfill(2) + '.csv', \n",
    "                set_last_id_num=set_last_id_num, \n",
    "                missing_value=missing_value, \n",
    "                sizes=[74, 75], \n",
    "                pred_sizes=[1, 152], \n",
    "                additional=True, \n",
    "                two_step=True,\n",
    "            )\n",
    "        )\n",
    "        counter += 1\n",
    "        \n",
    "        print('Result %i'%(counter))\n",
    "        results.append(\n",
    "            main(\n",
    "                'result_' + str(counter).zfill(2) + '.csv', \n",
    "                set_last_id_num=set_last_id_num, \n",
    "                missing_value=missing_value, \n",
    "                sizes=[74, _], \n",
    "                pred_sizes=[153, _], \n",
    "                additional=False, \n",
    "                two_step=False,\n",
    "            )\n",
    "        )\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 결과 및 결언\n",
    "#### Conclusion & Discussion\n",
    "- 1) 생성된 18개 결과끼리의 1-R2 score, SAMPE를 계산합니다. (보기 편하게 각각 10000, 10을 곱해줍니다.)\n",
    "- 2) 각 결과에 대한 1-R2 score, SAMPE에 대해 전체 결과의 1-R2 score, SMAPE의 중간값보다 작은 결과만 선별합니다.\n",
    "- 3) 선별된 결과를 평균하여 최종 submission.csv 를 생성합니다.\n",
    "- 4) Public score: 27.274358, Private score: 27.415830"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = 'temp/'\n",
    "file_list = os.listdir(dir_path)\n",
    "df_list = []\n",
    "for i, file in enumerate(file_list):\n",
    "    if file[-4:] == '.csv':\n",
    "        print(file)\n",
    "        df = pd.read_csv(dir_path + file)\n",
    "        df_list.append(df)\n",
    "print('')\n",
    "    \n",
    "column_1 = df_list[0].columns[0]\n",
    "column_2 = df_list[0].columns[1:]\n",
    "meter_id = df_list[0][column_1].values\n",
    "meter_id = meter_id.reshape(len(meter_id), 1)\n",
    "\n",
    "values = []\n",
    "for df in df_list:\n",
    "    value = df[column_2].values\n",
    "    values.append(value)\n",
    "values = np.array(values)\n",
    "\n",
    "scores_1 = []\n",
    "scores_2 = []\n",
    "for i in range(values.shape[0]):\n",
    "    tmp_1 = []\n",
    "    tmp_2 = []\n",
    "    for j in range(values.shape[0]):\n",
    "        score = (1-r2_score(values[i].flatten(), values[j].flatten()))*10000\n",
    "        tmp_1.append(score)\n",
    "        score = smape(values[i], values[j])*10\n",
    "        tmp_2.append(score)\n",
    "    scores_1.append(tmp_1)\n",
    "    scores_2.append(tmp_2)\n",
    "scores_1 = np.array(scores_1)\n",
    "scores_2 = np.array(scores_2)\n",
    "\n",
    "print('1 - R2 score')\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "ax.matshow(scores_1, cmap='Pastel1')\n",
    "for (i, j), z in np.ndenumerate(scores_1):\n",
    "    ax.text(i, j, '{:0.0f}'.format(z), ha='center', va='center')\n",
    "plt.show()\n",
    "\n",
    "print('SMAPE')\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "ax.matshow(scores_2, cmap='Pastel1')\n",
    "for (i, j), z in np.ndenumerate(scores_2):\n",
    "    ax.text(i, j, '{:0.0f}'.format(z), ha='center', va='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_1_mean = np.mean(scores_1, axis=0)\n",
    "scores_2_mean = np.mean(scores_2, axis=0)\n",
    "outputs = []\n",
    "for i in range(len(scores_1_mean)):\n",
    "    if (scores_1_mean[i] &lt;= np.median(scores_1_mean)) and (scores_2_mean[i] &lt;= np.median(scores_2_mean)):\n",
    "        print(str(i).zfill(2) + ', R2: %0.4f, SMAPE: %0.4f'%(scores_1_mean[i], scores_2_mean[i]))\n",
    "        outputs.append(values[i])\n",
    "outputs = np.array(outputs)\n",
    "output = np.mean(outputs, axis=0)\n",
    "output = np.append(meter_id, output, axis=1)\n",
    "column = list([column_1]) + list(column_2)\n",
    "df = pd.DataFrame(output, columns=column)\n",
    "df.to_csv('submission.csv', header=True, index=False)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
